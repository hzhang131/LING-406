{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unigram based naive bayes from scratch.\n",
    "import nltk \n",
    "import numpy \n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from nltk.corpus import movie_reviews \n",
    "import random\n",
    "document = [(movie_reviews.words(file_id),category) for file_id in movie_reviews.fileids() for category in movie_reviews.categories(file_id)]\n",
    "random.shuffle(document)\n",
    "train_set, test_set = model_selection.train_test_split(document,test_size = 0.2)\n",
    "pos_size = 0\n",
    "neg_size = 0\n",
    "token_pos_count = {}\n",
    "token_neg_count = {}\n",
    "for sample in train_set:\n",
    "    if sample[1] == 'pos':\n",
    "        for word in sample[0]:\n",
    "            if word not in token_pos_count:\n",
    "                token_pos_count[word] = 1\n",
    "            else:\n",
    "                token_pos_count[word] += 1\n",
    "            pos_size += 1\n",
    "    else:\n",
    "        for word in sample[0]:\n",
    "            if word not in token_neg_count:\n",
    "                token_neg_count[word] = 1\n",
    "            else:\n",
    "                token_neg_count[word] += 1\n",
    "            neg_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 79.75 %\n",
      "Precision 86.3905325443787 %\n",
      "Recall 71.56862745098039 %\n",
      "F1-Score 78.28418230563003 %\n"
     ]
    }
   ],
   "source": [
    "# Testing with naive bayes\n",
    "sp = 1\n",
    "correct_guesses = 0\n",
    "total_guesses = 0\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "for sample in test_set:\n",
    "    prob_pos = 0.0\n",
    "    prob_neg = 0.0\n",
    "    for word in sample[0]:\n",
    "        if word in token_pos_count:\n",
    "            prob_pos += numpy.log((token_pos_count.get(word) + sp) / (pos_size + sp * len(token_pos_count)))\n",
    "        else:\n",
    "            prob_pos += numpy.log(sp/(pos_size + sp * len(token_pos_count)))\n",
    "        if word in token_neg_count:\n",
    "            prob_neg += numpy.log((token_neg_count.get(word) + sp) / (neg_size + sp * len(token_neg_count)))\n",
    "        else:\n",
    "            prob_neg += numpy.log(sp/(neg_size + sp * len(token_neg_count)))\n",
    "\n",
    "    if sample[1] == 'pos':\n",
    "        if prob_pos >= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "        \n",
    "    else:\n",
    "        if prob_pos <= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_negative += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    total_guesses += 1\n",
    "    \n",
    "print('Accuracy', correct_guesses/total_guesses * 100, '%')\n",
    "print('Precision', true_positive/ (true_positive + false_positive) * 100, '%')\n",
    "print('Recall', true_positive/ (true_positive + false_negative) * 100, '%')\n",
    "print('F1-Score', 200 * (true_positive/ (true_positive + false_positive) * true_positive/ (true_positive + false_negative))/(true_positive/ (true_positive + false_positive) + true_positive/ (true_positive + false_negative)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with different features. (tf-idf)\n",
    "import nltk \n",
    "import numpy \n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from nltk.corpus import movie_reviews \n",
    "import random\n",
    "document = [(movie_reviews.words(file_id),category) for file_id in movie_reviews.fileids() for category in movie_reviews.categories(file_id)]\n",
    "random.shuffle(document)\n",
    "train_set, test_set = model_selection.train_test_split(document,test_size = 0.2)\n",
    "pos_size = 0\n",
    "neg_size = 0\n",
    "token_pos_count = {}\n",
    "token_neg_count = {}\n",
    "for sample in train_set:\n",
    "    if sample[1] == 'pos':\n",
    "        for word in sample[0]:\n",
    "            if word not in token_pos_count:\n",
    "                token_pos_count[word] = 1\n",
    "            else:\n",
    "                token_pos_count[word] += 1\n",
    "            pos_size += 1\n",
    "    else:\n",
    "        for word in sample[0]:\n",
    "            if word not in token_neg_count:\n",
    "                token_neg_count[word] = 1\n",
    "            else:\n",
    "                token_neg_count[word] += 1\n",
    "            neg_size += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 67.0 %\n",
      "Precision 64.54545454545455 %\n",
      "Recall 72.44897959183673 %\n",
      "F1-Score 68.26923076923076 %\n"
     ]
    }
   ],
   "source": [
    "# Testing with naive bayes\n",
    "sp = 1\n",
    "correct_guesses = 0\n",
    "total_guesses = 0\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "shown = []\n",
    "\n",
    "for sample in test_set:\n",
    "    shown_time = {}\n",
    "    for word in sample[0]:\n",
    "        if word not in shown_time:\n",
    "            shown_time[word] = 1\n",
    "        else:\n",
    "            shown_time[word] += 1\n",
    "    shown.append(shown_time)\n",
    "        \n",
    "for sample, shown_time in zip(test_set, shown):\n",
    "    prob_pos = 0.0\n",
    "    prob_neg = 0.0\n",
    "    for word in sample[0]:\n",
    "        if word in token_pos_count and word in shown_time:\n",
    "            prob_pos += shown_time[word] / len(sample[0]) * numpy.log((token_pos_count.get(word) + sp) / (pos_size + sp * len(token_pos_count))) \n",
    "        elif word not in token_pos_count and word in shown_time:\n",
    "            prob_pos += numpy.log(sp/(pos_size + sp * len(token_pos_count)))\n",
    "        else:\n",
    "            prob_pos += 0\n",
    "        if word in token_neg_count and word in shown_time:\n",
    "            prob_neg += shown_time[word] / len(sample[0]) * numpy.log((token_neg_count.get(word) + sp) / (neg_size + sp * len(token_neg_count)))\n",
    "        elif word not in token_neg_count and word in shown_time:\n",
    "            prob_neg += numpy.log(sp/(neg_size + sp * len(token_neg_count)))\n",
    "        else:\n",
    "            prob_neg += 0\n",
    "\n",
    "    if sample[1] == 'pos':\n",
    "        if prob_pos >= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "        \n",
    "    else:\n",
    "        if prob_pos <= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_negative += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    total_guesses += 1\n",
    "    \n",
    "print('Accuracy', correct_guesses/total_guesses * 100, '%')\n",
    "print('Precision', true_positive/ (true_positive + false_positive) * 100, '%')\n",
    "print('Recall', true_positive/ (true_positive + false_negative) * 100, '%')\n",
    "print('F1-Score', 200 * (true_positive/ (true_positive + false_positive) * true_positive/ (true_positive + false_negative))/(true_positive/ (true_positive + false_positive) + true_positive/ (true_positive + false_negative)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select non-puncts.\n",
    "import nltk \n",
    "import numpy \n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from nltk.corpus import movie_reviews \n",
    "import random\n",
    "document = [(movie_reviews.words(file_id),category) for file_id in movie_reviews.fileids() for category in movie_reviews.categories(file_id)]\n",
    "random.shuffle(document)\n",
    "train_set, test_set = model_selection.train_test_split(document,test_size = 0.2)\n",
    "pos_size = 0\n",
    "neg_size = 0\n",
    "token_pos_count = {}\n",
    "token_neg_count = {}\n",
    "punct_list = [',', '.', '\"','\\'', ';', ':', '{', '}', '[', ']', '|', '_', '-', '+', '=']\n",
    "for sample in train_set:\n",
    "    if sample[1] == 'pos':\n",
    "        for word in sample[0]:\n",
    "            if word in punct_list:\n",
    "                continue\n",
    "            if word not in token_pos_count:\n",
    "                token_pos_count[word] = 1\n",
    "            else:\n",
    "                token_pos_count[word] += 1\n",
    "            pos_size += 1\n",
    "    else:\n",
    "        for word in sample[0]:\n",
    "            if word in punct_list:\n",
    "                continue\n",
    "            if word not in token_neg_count:\n",
    "                token_neg_count[word] = 1\n",
    "            else:\n",
    "                token_neg_count[word] += 1\n",
    "            neg_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 82.0 %\n",
      "Precision 84.70588235294117 %\n",
      "Recall 75.78947368421053 %\n",
      "F1-Score 80.0 %\n"
     ]
    }
   ],
   "source": [
    "# Testing with naive bayes\n",
    "sp = 1\n",
    "correct_guesses = 0\n",
    "total_guesses = 0\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "for sample in test_set:\n",
    "    prob_pos = 0.0\n",
    "    prob_neg = 0.0\n",
    "    for word in sample[0]:\n",
    "        if word in punct_list:\n",
    "            continue\n",
    "        if word in token_pos_count:\n",
    "            prob_pos += numpy.log((token_pos_count.get(word) + sp) / (pos_size + sp * len(token_pos_count)))\n",
    "        else:\n",
    "            prob_pos += numpy.log(sp/(pos_size + sp * len(token_pos_count)))\n",
    "        if word in token_neg_count:\n",
    "            prob_neg += numpy.log((token_neg_count.get(word) + sp) / (neg_size + sp * len(token_neg_count)))\n",
    "        else:\n",
    "            prob_neg += numpy.log(sp/(neg_size + sp * len(token_neg_count)))\n",
    "\n",
    "    if sample[1] == 'pos':\n",
    "        if prob_pos >= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "        \n",
    "    else:\n",
    "        if prob_pos <= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_negative += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    total_guesses += 1\n",
    "    \n",
    "print('Accuracy', correct_guesses/total_guesses * 100, '%')\n",
    "print('Precision', true_positive/ (true_positive + false_positive) * 100, '%')\n",
    "print('Recall', true_positive/ (true_positive + false_negative) * 100, '%')\n",
    "print('F1-Score', 200 * (true_positive/ (true_positive + false_positive) * true_positive/ (true_positive + false_negative))/(true_positive/ (true_positive + false_positive) + true_positive/ (true_positive + false_negative)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select non-puncts.\n",
    "import nltk \n",
    "import numpy \n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from nltk.corpus import movie_reviews \n",
    "import random\n",
    "document = [(movie_reviews.words(file_id),category) for file_id in movie_reviews.fileids() for category in movie_reviews.categories(file_id)]\n",
    "random.shuffle(document)\n",
    "train_set, test_set = model_selection.train_test_split(document,test_size = 0.2)\n",
    "pos_size = 0\n",
    "neg_size = 0\n",
    "token_pos_count = {}\n",
    "token_neg_count = {}\n",
    "punct_list = [',', '.', '\"','\\'', ';', ':', '{', '}', '[', ']', '|', '_', '-', '+', '=']\n",
    "for sample in train_set:\n",
    "    if sample[1] == 'pos':\n",
    "        for word in sample[0]:\n",
    "            if word not in punct_list:\n",
    "                continue\n",
    "            if word not in token_pos_count:\n",
    "                token_pos_count[word] = 1\n",
    "            else:\n",
    "                token_pos_count[word] += 1\n",
    "            pos_size += 1\n",
    "    else:\n",
    "        for word in sample[0]:\n",
    "            if word not in punct_list:\n",
    "                continue\n",
    "            if word not in token_neg_count:\n",
    "                token_neg_count[word] = 1\n",
    "            else:\n",
    "                token_neg_count[word] += 1\n",
    "            neg_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 58.25 %\n",
      "Precision 57.89473684210527 %\n",
      "Recall 55.83756345177665 %\n",
      "F1-Score 56.84754521963824 %\n"
     ]
    }
   ],
   "source": [
    "# Testing with naive bayes\n",
    "sp = 1\n",
    "correct_guesses = 0\n",
    "total_guesses = 0\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "for sample in test_set:\n",
    "    prob_pos = 0.0\n",
    "    prob_neg = 0.0\n",
    "    for word in sample[0]:\n",
    "        if word not in punct_list:\n",
    "            continue\n",
    "        if word in token_pos_count:\n",
    "            prob_pos += numpy.log((token_pos_count.get(word) + sp) / (pos_size + sp * len(token_pos_count)))\n",
    "        else:\n",
    "            prob_pos += numpy.log(sp/(pos_size + sp * len(token_pos_count)))\n",
    "        if word in token_neg_count:\n",
    "            prob_neg += numpy.log((token_neg_count.get(word) + sp) / (neg_size + sp * len(token_neg_count)))\n",
    "        else:\n",
    "            prob_neg += numpy.log(sp/(neg_size + sp * len(token_neg_count)))\n",
    "\n",
    "    if sample[1] == 'pos':\n",
    "        if prob_pos >= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "        \n",
    "    else:\n",
    "        if prob_pos <= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_negative += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    total_guesses += 1\n",
    "    \n",
    "print('Accuracy', correct_guesses/total_guesses * 100, '%')\n",
    "print('Precision', true_positive/ (true_positive + false_positive) * 100, '%')\n",
    "print('Recall', true_positive/ (true_positive + false_negative) * 100, '%')\n",
    "print('F1-Score', 200 * (true_positive/ (true_positive + false_positive) * true_positive/ (true_positive + false_negative))/(true_positive/ (true_positive + false_positive) + true_positive/ (true_positive + false_negative)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select non-puncts.\n",
    "import nltk \n",
    "import numpy \n",
    "from nltk import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from nltk.corpus import movie_reviews \n",
    "import random\n",
    "document = [(movie_reviews.words(file_id),category) for file_id in movie_reviews.fileids() for category in movie_reviews.categories(file_id)]\n",
    "# random.shuffle(document)\n",
    "new_document = []\n",
    "pos_list = ['NN', 'NNS', 'VB', 'VBS', 'VBG', 'RB', 'JJ', 'VBP']\n",
    "for sample in document:\n",
    "    string = ''\n",
    "    for word in sample[0]:\n",
    "        string += word\n",
    "        string += ' '\n",
    "    string = word_tokenize(string)\n",
    "    local = nltk.pos_tag(string)\n",
    "    new_local = (local, sample[1])\n",
    "    new_document.append(new_local)\n",
    "\n",
    "random.shuffle(new_document)\n",
    "token_pos_count = {}\n",
    "token_neg_count = {}\n",
    "train_set, test_set = model_selection.train_test_split(new_document,test_size = 0.2)\n",
    "pos_size = 0\n",
    "neg_size = 0\n",
    "\n",
    "for sample in train_set:\n",
    "    if sample[1] == 'pos':\n",
    "        for word in sample[0]:\n",
    "            if word[1] not in pos_list:\n",
    "                continue\n",
    "            if word[0] not in token_pos_count:\n",
    "                token_pos_count[word[0]] = 1\n",
    "            else:\n",
    "                token_pos_count[word[0]] += 1\n",
    "            pos_size += 1\n",
    "    else:\n",
    "        for word in sample[0]:\n",
    "            if word[1] not in pos_list:\n",
    "                continue\n",
    "            if word[0] not in token_neg_count:\n",
    "                token_neg_count[word[0]] = 1\n",
    "            else:\n",
    "                token_neg_count[word[0]] += 1\n",
    "            neg_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 81.75 %\n",
      "Precision 84.04907975460122 %\n",
      "Recall 74.45652173913044 %\n",
      "F1-Score 78.96253602305475 %\n"
     ]
    }
   ],
   "source": [
    "# Testing with naive bayes\n",
    "sp = 1\n",
    "correct_guesses = 0\n",
    "total_guesses = 0\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "true_negative = 0\n",
    "false_negative = 0\n",
    "for sample in test_set:\n",
    "    prob_pos = 0.0\n",
    "    prob_neg = 0.0\n",
    "    for word in sample[0]:\n",
    "        if word[1] not in pos_list:\n",
    "            continue\n",
    "        if word[0] in token_pos_count:\n",
    "            prob_pos += numpy.log((token_pos_count.get(word[0]) + sp) / (pos_size + sp * len(token_pos_count)))\n",
    "        else:\n",
    "            prob_pos += numpy.log(sp/(pos_size + sp * len(token_pos_count)))\n",
    "        if word[0] in token_neg_count:\n",
    "            prob_neg += numpy.log((token_neg_count.get(word[0]) + sp) / (neg_size + sp * len(token_neg_count)))\n",
    "        else:\n",
    "            prob_neg += numpy.log(sp/(neg_size + sp * len(token_neg_count)))\n",
    "\n",
    "    if sample[1] == 'pos':\n",
    "        if prob_pos >= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "        \n",
    "    else:\n",
    "        if prob_pos <= prob_neg:\n",
    "            correct_guesses += 1\n",
    "            true_negative += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "    total_guesses += 1\n",
    "    \n",
    "print('Accuracy', correct_guesses/total_guesses * 100, '%')\n",
    "print('Precision', true_positive/ (true_positive + false_positive) * 100, '%')\n",
    "print('Recall', true_positive/ (true_positive + false_negative) * 100, '%')\n",
    "print('F1-Score', 200 * (true_positive/ (true_positive + false_positive) * true_positive/ (true_positive + false_negative))/(true_positive/ (true_positive + false_positive) + true_positive/ (true_positive + false_negative)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
