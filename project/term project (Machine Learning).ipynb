{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "document = [(movie_reviews.words(file_id),category) for file_id in movie_reviews.fileids() for category in movie_reviews.categories(file_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pos -> 1, neg -> 0.\n",
    "word_dict = {}\n",
    "word_tag = 0\n",
    "sent_tag = 0\n",
    "grand_list = []\n",
    "class_code = []\n",
    "for word in movie_reviews.words():\n",
    "    if word not in word_dict:\n",
    "        word_dict[word] = word_tag\n",
    "        word_tag += 0.01     \n",
    "\n",
    "random.shuffle(document) # To get rid of these zero division warnings.\n",
    "\n",
    "for sample in document:\n",
    "    if sample[1] == 'pos':\n",
    "        class_code.append(1)\n",
    "    else:\n",
    "        class_code.append(0)\n",
    "    \n",
    "    local_list = []\n",
    "    count = 0\n",
    "    for word in sample[0]:\n",
    "        if count == 95:\n",
    "            break\n",
    "        local_list.append(word_dict[word])\n",
    "        count += 1\n",
    "    grand_list.append(local_list)\n",
    "    \n",
    "class_code = np.array(class_code, dtype=float)\n",
    "\n",
    "df = pd.DataFrame(grand_list, dtype = float)\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.dropna() # I have no idea where these NaNs came from. Fuck!!!!!\n",
    "\n",
    "Y = class_code\n",
    "X = scipy.sparse.csr_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tAverage Macro F1 for Naive_Bayes:\t\t 0.651112244403391\n",
      "\tAverage Macro Precision for Naive_Bayes:\t 0.6622860857311929\n",
      "\tAverage Macro Recall for Naive_Bayes:\t\t 0.6571552683098333\n",
      "\tAverage Macro Accuracy for Naive_Bayes:\t\t 0.6577575757575758\n",
      "Now classifying Decision_Tree\n",
      "\tAverage Macro F1 for Decision_Tree:\t\t 0.9506558435490311\n",
      "\tAverage Macro Precision for Decision_Tree:\t 0.9522443639291465\n",
      "\tAverage Macro Recall for Decision_Tree:\t\t 0.952784090909091\n",
      "\tAverage Macro Accuracy for Decision_Tree:\t\t 0.9517171717171719\n",
      "Now classifying Nearest Neighbors\n",
      "\tAverage Macro F1 for Nearest Neighbors:\t\t 0.5734981794565313\n",
      "\tAverage Macro Precision for Nearest Neighbors:\t 0.7273066210969042\n",
      "\tAverage Macro Recall for Nearest Neighbors:\t\t 0.6241351862095972\n",
      "\tAverage Macro Accuracy for Nearest Neighbors:\t\t 0.6202373737373736\n"
     ]
    }
   ],
   "source": [
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train.todense(), y_train)\n",
    "    y_pred = clf.predict(X_test.todense())\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return f1, precision, recall, accuracy\n",
    "\n",
    "names = ['Naive_Bayes', 'Decision_Tree', 'Nearest Neighbors']\n",
    "classifiers =  [GaussianNB(), \n",
    "                DecisionTreeClassifier(random_state=1),\n",
    "                KNeighborsClassifier(5)]\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "\n",
    "    print('Now classifying', name)\n",
    "\n",
    "    # Fold the data 20 times\n",
    "    kf = KFold(n_splits = 20)\n",
    "    foldCounter = 0\n",
    "    aList, bList, cList, dList= list(), list(), list(), list()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index[0] : train_index[len(train_index)-1]+1], X[test_index[0] : test_index[len(test_index)-1]+1]\n",
    "        y_train, y_test = Y[train_index[0] : train_index[len(train_index)-1]+1], Y[test_index[0] : test_index[len(test_index)-1]+1]\n",
    "        f1, precision, recall, accuracy= buildClassifiers(clf, X_train, X_test, y_train, y_test)\n",
    "        aList.append(f1)\n",
    "        bList.append(precision)\n",
    "        cList.append(recall)\n",
    "        dList.append(accuracy)\n",
    "\n",
    "    print(\"\\tAverage Macro F1 for {}:\\t\\t\".format(name), np.mean(aList))\n",
    "    print(\"\\tAverage Macro Precision for {}:\\t\".format(name), np.mean(bList))\n",
    "    print(\"\\tAverage Macro Recall for {}:\\t\\t\".format(name), np.mean(cList))\n",
    "    print(\"\\tAverage Macro Accuracy for {}:\\t\\t\".format(name), np.mean(dList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "document = [(movie_reviews.words(file_id),category) for file_id in movie_reviews.fileids() for category in movie_reviews.categories(file_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622.1699999995792\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "word_tag = 0\n",
    "sent_tag = 0\n",
    "grand_list = []\n",
    "class_code = []\n",
    "new_document = []\n",
    "\n",
    "for sample in document:\n",
    "    string = ''\n",
    "    for word in sample[0]:\n",
    "        string += word\n",
    "        string += ' '\n",
    "    string = word_tokenize(string)\n",
    "    local = nltk.pos_tag(string)\n",
    "    new_local = (local, sample[1])\n",
    "    new_document.append(new_local)\n",
    "\n",
    "for sample in new_document:\n",
    "    for word in sample[0]:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word] = word_tag\n",
    "            word_tag += 0.01     \n",
    "\n",
    "print(word_tag)\n",
    "\n",
    "random.shuffle(new_document) # To get rid of these zero division warnings.\n",
    "\n",
    "for sample in new_document:\n",
    "    if sample[1] == 'pos':\n",
    "        class_code.append(1)\n",
    "    else:\n",
    "        class_code.append(0)\n",
    "    \n",
    "    local_list = []\n",
    "    count = 0\n",
    "    for word in sample[0]:\n",
    "        if count == 95:\n",
    "            break\n",
    "        local_list.append(word_dict[word])\n",
    "        count += 1\n",
    "    grand_list.append(local_list)\n",
    "    \n",
    "class_code = np.array(class_code, dtype=float)\n",
    "\n",
    "df = pd.DataFrame(grand_list, dtype = float)\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.dropna() # I have no idea where these NaNs came from. Fuck!!!!!\n",
    "\n",
    "Y = class_code\n",
    "X = scipy.sparse.csr_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tAverage Macro F1 for Naive_Bayes:\t\t 0.5580782156013722\n",
      "\tAverage Macro Precision for Naive_Bayes:\t 0.5690759556014228\n",
      "\tAverage Macro Recall for Naive_Bayes:\t\t 0.5672194513382942\n",
      "\tAverage Macro Accuracy for Naive_Bayes:\t\t 0.5642626262626262\n",
      "Now classifying Decision_Tree\n",
      "\tAverage Macro F1 for Decision_Tree:\t\t 0.9439293114654232\n",
      "\tAverage Macro Precision for Decision_Tree:\t 0.9440668498168497\n",
      "\tAverage Macro Recall for Decision_Tree:\t\t 0.9439709415658009\n",
      "\tAverage Macro Accuracy for Decision_Tree:\t\t 0.9442373737373737\n",
      "Now classifying Nearest Neighbors\n",
      "\tAverage Macro F1 for Nearest Neighbors:\t\t 0.67299640885349\n",
      "\tAverage Macro Precision for Nearest Neighbors:\t 0.6865377426456968\n",
      "\tAverage Macro Recall for Nearest Neighbors:\t\t 0.680391850466464\n",
      "\tAverage Macro Accuracy for Nearest Neighbors:\t\t 0.6832474747474747\n"
     ]
    }
   ],
   "source": [
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train.todense(), y_train)\n",
    "    y_pred = clf.predict(X_test.todense())\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return f1, precision, recall, accuracy\n",
    "\n",
    "names = ['Naive_Bayes', 'Decision_Tree', 'Nearest Neighbors']\n",
    "classifiers =  [GaussianNB(), \n",
    "                DecisionTreeClassifier(random_state=1),\n",
    "                KNeighborsClassifier(5)]\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "\n",
    "    print('Now classifying', name)\n",
    "\n",
    "    # Fold the data 20 times\n",
    "    kf = KFold(n_splits = 20)\n",
    "    foldCounter = 0\n",
    "    aList, bList, cList, dList= list(), list(), list(), list()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index[0] : train_index[len(train_index)-1]+1], X[test_index[0] : test_index[len(test_index)-1]+1]\n",
    "        y_train, y_test = Y[train_index[0] : train_index[len(train_index)-1]+1], Y[test_index[0] : test_index[len(test_index)-1]+1]\n",
    "        f1, precision, recall, accuracy= buildClassifiers(clf, X_train, X_test, y_train, y_test)\n",
    "        aList.append(f1)\n",
    "        bList.append(precision)\n",
    "        cList.append(recall)\n",
    "        dList.append(accuracy)\n",
    "\n",
    "    print(\"\\tAverage Macro F1 for {}:\\t\\t\".format(name), np.mean(aList))\n",
    "    print(\"\\tAverage Macro Precision for {}:\\t\".format(name), np.mean(bList))\n",
    "    print(\"\\tAverage Macro Recall for {}:\\t\\t\".format(name), np.mean(cList))\n",
    "    print(\"\\tAverage Macro Accuracy for {}:\\t\\t\".format(name), np.mean(dList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "word_tag = 0\n",
    "sent_tag = 0\n",
    "grand_list = []\n",
    "class_code = []\n",
    "new_document = []\n",
    "\n",
    "for sample in document:\n",
    "    string = ''\n",
    "    for word in sample[0]:\n",
    "        string += word\n",
    "        string += ' '\n",
    "    string = word_tokenize(string)\n",
    "    local = nltk.pos_tag(string)\n",
    "    new_local = (local, sample[1])\n",
    "    new_document.append(new_local)\n",
    "\n",
    "for sample in new_document:\n",
    "    for word in sample[0]:\n",
    "        if word[1] not in word_dict:\n",
    "            word_dict[word[1]] = word_tag\n",
    "            word_tag += 1     \n",
    "\n",
    "print(word_tag)\n",
    "\n",
    "random.shuffle(new_document) # To get rid of these zero division warnings.\n",
    "\n",
    "for sample in new_document:\n",
    "    if sample[1] == 'pos':\n",
    "        class_code.append(1)\n",
    "    else:\n",
    "        class_code.append(0)\n",
    "    \n",
    "    local_list = []\n",
    "    count = 0\n",
    "    for word in sample[0]:\n",
    "        if count == 95:\n",
    "            break\n",
    "        local_list.append(word_dict[word[1]])\n",
    "        count += 1\n",
    "    grand_list.append(local_list)\n",
    "    \n",
    "class_code = np.array(class_code, dtype=float)\n",
    "\n",
    "df = pd.DataFrame(grand_list, dtype = float)\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.dropna() # I have no idea where these NaNs came from. Fuck!!!!!\n",
    "\n",
    "Y = class_code\n",
    "X = scipy.sparse.csr_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tAverage Macro F1 for Naive_Bayes:\t\t 0.5945666407104399\n",
      "\tAverage Macro Precision for Naive_Bayes:\t 0.5958112281776623\n",
      "\tAverage Macro Recall for Naive_Bayes:\t\t 0.5960295423283979\n",
      "\tAverage Macro Accuracy for Naive_Bayes:\t\t 0.5972828282828283\n",
      "Now classifying Decision_Tree\n",
      "\tAverage Macro F1 for Decision_Tree:\t\t 0.9527096415489273\n",
      "\tAverage Macro Precision for Decision_Tree:\t 0.9530015155066428\n",
      "\tAverage Macro Recall for Decision_Tree:\t\t 0.952961333878887\n",
      "\tAverage Macro Accuracy for Decision_Tree:\t\t 0.9527474747474749\n",
      "Now classifying Nearest Neighbors\n",
      "\tAverage Macro F1 for Nearest Neighbors:\t\t 0.6600389206706108\n",
      "\tAverage Macro Precision for Nearest Neighbors:\t 0.6702061004098779\n",
      "\tAverage Macro Recall for Nearest Neighbors:\t\t 0.6643329612096799\n",
      "\tAverage Macro Accuracy for Nearest Neighbors:\t\t 0.6707424242424241\n"
     ]
    }
   ],
   "source": [
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train.todense(), y_train)\n",
    "    y_pred = clf.predict(X_test.todense())\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return f1, precision, recall, accuracy\n",
    "\n",
    "names = ['Naive_Bayes', 'Decision_Tree', 'Nearest Neighbors']\n",
    "classifiers =  [GaussianNB(), \n",
    "                DecisionTreeClassifier(random_state=1),\n",
    "                KNeighborsClassifier(5)]\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "\n",
    "    print('Now classifying', name)\n",
    "\n",
    "    # Fold the data 20 times\n",
    "    kf = KFold(n_splits = 20)\n",
    "    foldCounter = 0\n",
    "    aList, bList, cList, dList= list(), list(), list(), list()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index[0] : train_index[len(train_index)-1]+1], X[test_index[0] : test_index[len(test_index)-1]+1]\n",
    "        y_train, y_test = Y[train_index[0] : train_index[len(train_index)-1]+1], Y[test_index[0] : test_index[len(test_index)-1]+1]\n",
    "        f1, precision, recall, accuracy= buildClassifiers(clf, X_train, X_test, y_train, y_test)\n",
    "        aList.append(f1)\n",
    "        bList.append(precision)\n",
    "        cList.append(recall)\n",
    "        dList.append(accuracy)\n",
    "\n",
    "    print(\"\\tAverage Macro F1 for {}:\\t\\t\".format(name), np.mean(aList))\n",
    "    print(\"\\tAverage Macro Precision for {}:\\t\".format(name), np.mean(bList))\n",
    "    print(\"\\tAverage Macro Recall for {}:\\t\\t\".format(name), np.mean(cList))\n",
    "    print(\"\\tAverage Macro Accuracy for {}:\\t\\t\".format(name), np.mean(dList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
